---
description: Ð£Ð·Ð»Ñ‹ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÐµÐ¹ Ñ‚ÐµÐºÑÑ‚Ð° LangChain
---

# Ð Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»Ð¸ Ñ‚ÐµÐºÑÑ‚Ð°

> **ðŸ“‹ Ð£Ð²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ðµ**: Ð”Ð°Ð½Ð½Ð°Ñ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ Ð¾ÑÐ½Ð¾Ð²Ð°Ð½Ð° Ð½Ð° Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ Flowise Ð¸ Ð² Ð½Ð°ÑÑ‚Ð¾ÑÑ‰ÐµÐµ Ð²Ñ€ÐµÐ¼Ñ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ÑÑ Ð´Ð»Ñ Universo Platformo React. ÐÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ€Ð°Ð·Ð´ÐµÐ»Ñ‹ Ð¼Ð¾Ð³ÑƒÑ‚ Ð²ÑÐµ ÐµÑ‰Ðµ ÑÑÑ‹Ð»Ð°Ñ‚ÑŒÑÑ Ð½Ð° Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Flowise, ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ ÐµÑ‰Ðµ Ð½Ðµ Ð±Ñ‹Ð»Ð° Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð° Ð´Ð»Ñ ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡Ð½Ñ‹Ñ… Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚ÐµÐ¹ Universo Platformo.

> **ðŸ”„ Ð¡Ñ‚Ð°Ñ‚ÑƒÑ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ð°**: Ð­Ñ‚Ð¾Ñ‚ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ Ð¿ÐµÑ€ÐµÐ²ÐµÐ´ÐµÐ½ Ñ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð³Ð¾ ÑÐ·Ñ‹ÐºÐ° Ð¸ Ð¿Ñ€Ð¾Ñ…Ð¾Ð´Ð¸Ñ‚ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð°Ð´Ð°Ð¿Ñ‚Ð°Ñ†Ð¸Ð¸ Ð´Ð»Ñ Ñ€ÑƒÑÑÐºÐ¾ÑÐ·Ñ‹Ñ‡Ð½Ð¾Ð¹ Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ð¸Ð¸. Ð•ÑÐ»Ð¸ Ð²Ñ‹ Ð·Ð°Ð¼ÐµÑ‚Ð¸Ð»Ð¸ Ð½ÐµÑ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ Ð² Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ðµ Ð¸Ð»Ð¸ Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¸, Ð¿Ð¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, ÑÐ¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ issue Ð² Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ð¸Ð¸.

***

**ÐšÐ¾Ð³Ð´Ð° Ð²Ñ‹ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ñ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ð¼Ð¸ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸ Ñ‚ÐµÐºÑÑ‚Ð°, Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ Ñ€Ð°Ð·Ð±Ð¸Ñ‚ÑŒ ÑÑ‚Ð¾Ñ‚ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ñ‡Ð°ÑÑ‚Ð¸.**\
ÐšÐ°Ðº Ð±Ñ‹ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ ÑÑ‚Ð¾ Ð½Ð¸ Ð·Ð²ÑƒÑ‡Ð°Ð»Ð¾, Ð·Ð´ÐµÑÑŒ ÐµÑÑ‚ÑŒ Ð¼Ð½Ð¾Ð³Ð¾ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ð¸Ð°Ð»ÑŒÐ½Ð¾Ð¹ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸. Ð’ Ð¸Ð´ÐµÐ°Ð»Ðµ Ð²Ñ‹ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ðµ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ñ‹ Ñ‚ÐµÐºÑÑ‚Ð° Ð²Ð¼ÐµÑÑ‚Ðµ. Ð¢Ð¾, Ñ‡Ñ‚Ð¾ Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚ "ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ð¹", Ð¼Ð¾Ð¶ÐµÑ‚ Ð·Ð°Ð²Ð¸ÑÐµÑ‚ÑŒ Ð¾Ñ‚ Ñ‚Ð¸Ð¿Ð° Ñ‚ÐµÐºÑÑ‚Ð°. Ð­Ñ‚Ð¾Ñ‚ Ñ€Ð°Ð·Ð´ÐµÐ» Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÑ‚ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÐ¿Ð¾ÑÐ¾Ð±Ð¾Ð² ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ ÑÑ‚Ð¾.

## Ð§Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ðµ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»Ð¸ Ñ‚ÐµÐºÑÑ‚Ð°?

Ð Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»Ð¸ Ñ‚ÐµÐºÑÑ‚Ð° - ÑÑ‚Ð¾ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ Ñ€Ð°Ð·Ð±Ð¸ÐµÐ½Ð¸Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð½Ð° ÑƒÐ¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼Ñ‹Ðµ Ñ‡Ð°ÑÑ‚Ð¸ (Ñ‡Ð°Ð½ÐºÐ¸), ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ:

- **Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÑŽÑ‚ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ ÑÐ²ÑÐ·Ð½Ð¾ÑÑ‚ÑŒ** - Ð´ÐµÑ€Ð¶Ð°Ñ‚ ÑÐ²ÑÐ·Ð°Ð½Ð½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð²Ð¼ÐµÑÑ‚Ðµ
- **ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€ÑƒÑŽÑ‚ Ñ€Ð°Ð·Ð¼ÐµÑ€** Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸ Ð¸ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ñ‹Ð¼Ð¸ Ð±Ð°Ð·Ð°Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…
- **ÐžÐ±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÑŽÑ‚ Ð¿ÐµÑ€ÐµÐºÑ€Ñ‹Ñ‚Ð¸Ðµ** Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° Ð¼ÐµÐ¶Ð´Ñƒ Ñ‡Ð°ÑÑ‚ÑÐ¼Ð¸
- **ÐÐ´Ð°Ð¿Ñ‚Ð¸Ñ€ÑƒÑŽÑ‚ÑÑ Ðº Ñ‚Ð¸Ð¿Ñƒ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°** - ÐºÐ¾Ð´, markdown, HTML, Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚
- **Ð£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÑŽÑ‚ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²** Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹

### Ð—Ð°Ñ‡ÐµÐ¼ Ð½ÑƒÐ¶Ð½Ð¾ Ñ€Ð°Ð·Ð±Ð¸ÐµÐ½Ð¸Ðµ Ñ‚ÐµÐºÑÑ‚Ð°?

```yaml
reasons_for_text_splitting:
  performance:
    - "Ð£ÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð¸ÑÐºÐ° Ð¿Ð¾ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð½Ð¾Ð¹ Ð±Ð°Ð·Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…"
    - "Ð¡Ð½Ð¸Ð¶ÐµÐ½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ LLM"
    - "ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ð°Ð¼ÑÑ‚Ð¸"
  
  quality:
    - "ÐŸÐ¾Ð²Ñ‹ÑˆÐµÐ½Ð¸Ðµ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ð¾Ð¸ÑÐºÐ°"
    - "Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ðµ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²"
    - "Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° Ð² Ð½ÐµÐ±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð°Ñ…"
  
  cost:
    - "Ð¡Ð½Ð¸Ð¶ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸"
    - "ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð·Ð°Ñ‚Ñ€Ð°Ñ‚ Ð½Ð° API Ð²Ñ‹Ð·Ð¾Ð²Ñ‹"
    - "Ð­Ñ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²"
  
  technical:
    - "Ð¡Ð¾Ð±Ð»ÑŽÐ´ÐµÐ½Ð¸Ðµ Ð»Ð¸Ð¼Ð¸Ñ‚Ð¾Ð² Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð¼Ð¾Ð´ÐµÐ»Ð¸"
    - "ÐŸÐ°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð¾Ð²"
    - "ÐœÐ°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€ÑƒÐµÐ¼Ð¾ÑÑ‚ÑŒ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹"
```

## ÐŸÑ€Ð¸Ð½Ñ†Ð¸Ð¿ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÐµÐ¹ Ñ‚ÐµÐºÑÑ‚Ð°

**ÐÐ° Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¼ ÑƒÑ€Ð¾Ð²Ð½Ðµ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»Ð¸ Ñ‚ÐµÐºÑÑ‚Ð° Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÑŽÑ‚ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¼ Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð¼:**

1. **Ð Ð°Ð·Ð±Ð¸Ð²Ð°ÑŽÑ‚ Ñ‚ÐµÐºÑÑ‚** Ð½Ð° Ð½ÐµÐ±Ð¾Ð»ÑŒÑˆÐ¸Ðµ, ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð·Ð½Ð°Ñ‡Ð¸Ð¼Ñ‹Ðµ Ñ‡Ð°ÑÑ‚Ð¸ (Ñ‡Ð°ÑÑ‚Ð¾ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ).
2. **ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽÑ‚ Ð¾Ð±ÑŠÐµÐ´Ð¸Ð½ÑÑ‚ÑŒ** ÑÑ‚Ð¸ Ð½ÐµÐ±Ð¾Ð»ÑŒÑˆÐ¸Ðµ Ñ‡Ð°ÑÑ‚Ð¸ Ð² Ð±Ð¾Ð»ÐµÐµ ÐºÑ€ÑƒÐ¿Ð½ÑƒÑŽ Ñ‡Ð°ÑÑ‚ÑŒ, Ð¿Ð¾ÐºÐ° Ð½Ðµ Ð´Ð¾ÑÑ‚Ð¸Ð³Ð½ÑƒÑ‚ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð½Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° (Ð¸Ð·Ð¼ÐµÑ€ÑÐµÐ¼Ð¾Ð³Ð¾ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¹ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÐµÐ¹).
3. **ÐšÐ°Ðº Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð¾ÑÑ‚Ð¸Ð³Ð°ÑŽÑ‚ ÑÑ‚Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð°**, Ð´ÐµÐ»Ð°ÑŽÑ‚ ÑÑ‚Ñƒ Ñ‡Ð°ÑÑ‚ÑŒ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¼ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð¾Ð¼ Ñ‚ÐµÐºÑÑ‚Ð°, Ð° Ð·Ð°Ñ‚ÐµÐ¼ Ð½Ð°Ñ‡Ð¸Ð½Ð°ÑŽÑ‚ ÑÐ¾Ð·Ð´Ð°Ð²Ð°Ñ‚ÑŒ Ð½Ð¾Ð²ÑƒÑŽ Ñ‡Ð°ÑÑ‚ÑŒ Ñ‚ÐµÐºÑÑ‚Ð° Ñ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¼ Ð¿ÐµÑ€ÐµÐºÑ€Ñ‹Ñ‚Ð¸ÐµÐ¼ (Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¼ÐµÐ¶Ð´Ñƒ Ñ‡Ð°ÑÑ‚ÑÐ¼Ð¸).

### ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ñ

```
Ð˜ÑÑ…Ð¾Ð´Ð½Ñ‹Ð¹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ â†’ ÐŸÑ€ÐµÐ´Ð²Ð°Ñ€Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ñ€Ð°Ð·Ð±Ð¸ÐµÐ½Ð¸Ðµ â†’ ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ð² Ñ‡Ð°Ð½ÐºÐ¸ â†’ Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿ÐµÑ€ÐµÐºÑ€Ñ‹Ñ‚Ð¸Ð¹ â†’ Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ñ‡Ð°Ð½ÐºÐ¸
        â†“                    â†“                      â†“                    â†“                    â†“
   Ð”Ð»Ð¸Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ â†’ ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ/Ð°Ð±Ð·Ð°Ñ†Ñ‹ â†’ Ð§Ð°Ð½ÐºÐ¸ Ð½ÑƒÐ¶Ð½Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° â†’ ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð½Ñ‹Ðµ ÑÐ²ÑÐ·Ð¸ â†’ Ð“Ð¾Ñ‚Ð¾Ð²Ñ‹Ðµ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ñ‹
```

**Ð­Ñ‚Ð¾ Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚, Ñ‡Ñ‚Ð¾ ÐµÑÑ‚ÑŒ Ð´Ð²Ðµ Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ð¾ÑÐ¸, Ð¿Ð¾ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¼ Ð²Ñ‹ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÑŒ ÑÐ²Ð¾Ð¹ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÑŒ Ñ‚ÐµÐºÑÑ‚Ð°:**

1. **ÐšÐ°Ðº Ñ€Ð°Ð·Ð±Ð¸Ð²Ð°ÐµÑ‚ÑÑ Ñ‚ÐµÐºÑÑ‚** - ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ñ
2. **ÐšÐ°Ðº Ð¸Ð·Ð¼ÐµÑ€ÑÐµÑ‚ÑÑ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ñ‡Ð°ÑÑ‚Ð¸** - Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ° Ñ€Ð°Ð·Ð¼ÐµÑ€Ð°

### Ð¡Ñ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ð¸ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ñ

```python
# Ð Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ð¸ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð°
splitting_strategies = {
    "character_based": {
        "description": "Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð¾ ÑÐ¸Ð¼Ð²Ð¾Ð»Ð°Ð¼",
        "separators": ["\n\n", "\n", " ", ""],
        "use_case": "ÐŸÑ€Ð¾ÑÑ‚Ñ‹Ðµ Ñ‚ÐµÐºÑÑ‚Ñ‹, Ð¾Ð±Ñ‰Ð¸Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹",
        "pros": ["ÐŸÑ€Ð¾ÑÑ‚Ð¾Ñ‚Ð°", "Ð£Ð½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ"],
        "cons": ["ÐœÐ¾Ð¶ÐµÑ‚ Ñ€Ð°Ð·Ñ€Ñ‹Ð²Ð°Ñ‚ÑŒ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÐµÐ´Ð¸Ð½Ð¸Ñ†Ñ‹"]
    },
    
    "recursive_character": {
        "description": "Ð ÐµÐºÑƒÑ€ÑÐ¸Ð²Ð½Ð¾Ðµ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð¾ ÑÐ¸Ð¼Ð²Ð¾Ð»Ð°Ð¼",
        "separators": ["\n\n", "\n", " ", ""],
        "use_case": "Ð‘Ð¾Ð»ÑŒÑˆÐ¸Ð½ÑÑ‚Ð²Ð¾ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²",
        "pros": ["Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ", "Ð“Ð¸Ð±ÐºÐ¾ÑÑ‚ÑŒ"],
        "cons": ["Ð¡Ð»Ð¾Ð¶Ð½ÐµÐµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°"]
    },
    
    "token_based": {
        "description": "Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð°Ð¼",
        "separators": "Ð¢Ð¾ÐºÐµÐ½Ñ‹ Ð¼Ð¾Ð´ÐµÐ»Ð¸",
        "use_case": "Ð¢Ð¾Ñ‡Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²",
        "pros": ["Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ", "Ð¡Ð¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð»Ð¸Ð¼Ð¸Ñ‚Ð°Ð¼ Ð¼Ð¾Ð´ÐµÐ»Ð¸"],
        "cons": ["Ð—Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¾Ñ‚ Ñ‚Ð¾ÐºÐµÐ½Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°"]
    },
    
    "semantic_based": {
        "description": "Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ",
        "separators": "Ð¡Ð¼Ñ‹ÑÐ»Ð¾Ð²Ñ‹Ðµ Ð³Ñ€Ð°Ð½Ð¸Ñ†Ñ‹",
        "use_case": "Ð’Ñ‹ÑÐ¾ÐºÐ¾ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°",
        "pros": ["ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ"],
        "cons": ["Ð’Ñ‹Ñ‡Ð¸ÑÐ»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ"]
    }
}
```

### ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð°

```python
# Ð¡Ð¿Ð¾ÑÐ¾Ð±Ñ‹ Ð¸Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ñ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° Ñ‡Ð°Ð½ÐºÐ¾Ð²
size_metrics = {
    "character_count": {
        "description": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²",
        "function": "len(text)",
        "pros": ["ÐŸÑ€Ð¾ÑÑ‚Ð¾Ñ‚Ð°", "Ð¡ÐºÐ¾Ñ€Ð¾ÑÑ‚ÑŒ"],
        "cons": ["ÐÐµ ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ñ‚Ð¾ÐºÐµÐ½Ñ‹ Ð¼Ð¾Ð´ÐµÐ»Ð¸"]
    },
    
    "token_count": {
        "description": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²",
        "function": "tokenizer.encode(text)",
        "pros": ["Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸", "Ð¡Ð¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð»Ð¸Ð¼Ð¸Ñ‚Ð°Ð¼"],
        "cons": ["Ð—Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¾Ñ‚ Ñ‚Ð¾ÐºÐµÐ½Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°", "ÐœÐµÐ´Ð»ÐµÐ½Ð½ÐµÐµ"]
    },
    
    "word_count": {
        "description": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÐ»Ð¾Ð²",
        "function": "len(text.split())",
        "pros": ["Ð˜Ð½Ñ‚ÑƒÐ¸Ñ‚Ð¸Ð²Ð½Ð¾ÑÑ‚ÑŒ", "Ð¯Ð·Ñ‹ÐºÐ¾Ð²Ð°Ñ Ð½ÐµÐ·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÑŒ"],
        "cons": ["ÐÐµÑ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð´Ð»Ñ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ñ… ÑÐ·Ñ‹ÐºÐ¾Ð²"]
    },
    
    "sentence_count": {
        "description": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹",
        "function": "sentence_tokenizer(text)",
        "pros": ["Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ñ†ÐµÐ»Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ"],
        "cons": ["Ð¡Ð»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ð³Ñ€Ð°Ð½Ð¸Ñ†"]
    }
}
```

## Ð’Ñ‹Ð±Ð¾Ñ€ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰ÐµÐ³Ð¾ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»Ñ

### ÐœÐ°Ñ‚Ñ€Ð¸Ñ†Ð° Ð²Ñ‹Ð±Ð¾Ñ€Ð° Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»Ñ

```python
# Ð ÑƒÐºÐ¾Ð²Ð¾Ð´ÑÑ‚Ð²Ð¾ Ð¿Ð¾ Ð²Ñ‹Ð±Ð¾Ñ€Ñƒ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»Ñ
splitter_selection_guide = {
    "document_types": {
        "plain_text": {
            "recommended": "RecursiveCharacterTextSplitter",
            "alternatives": ["CharacterTextSplitter"],
            "settings": {
                "chunk_size": 1000,
                "chunk_overlap": 200,
                "separators": ["\n\n", "\n", " ", ""]
            }
        },
        
        "markdown": {
            "recommended": "MarkdownTextSplitter",
            "alternatives": ["RecursiveCharacterTextSplitter"],
            "settings": {
                "chunk_size": 1000,
                "chunk_overlap": 200,
                "headers_to_split_on": [
                    ("#", "Header 1"),
                    ("##", "Header 2"),
                    ("###", "Header 3")
                ]
            }
        },
        
        "code": {
            "recommended": "CodeTextSplitter",
            "alternatives": ["RecursiveCharacterTextSplitter"],
            "settings": {
                "chunk_size": 1500,
                "chunk_overlap": 300,
                "language": "python"  # Ð¸Ð»Ð¸ Ð´Ñ€ÑƒÐ³Ð¾Ð¹ ÑÐ·Ñ‹Ðº
            }
        },
        
        "html": {
            "recommended": "HTMLToMarkdownTextSplitter",
            "alternatives": ["RecursiveCharacterTextSplitter"],
            "settings": {
                "chunk_size": 1000,
                "chunk_overlap": 200,
                "convert_to_markdown": True
            }
        },
        
        "academic_papers": {
            "recommended": "RecursiveCharacterTextSplitter",
            "alternatives": ["TokenTextSplitter"],
            "settings": {
                "chunk_size": 1500,
                "chunk_overlap": 300,
                "separators": ["\n\n", "\n", ". ", " ", ""]
            }
        },
        
        "legal_documents": {
            "recommended": "RecursiveCharacterTextSplitter",
            "alternatives": ["CharacterTextSplitter"],
            "settings": {
                "chunk_size": 800,
                "chunk_overlap": 150,
                "separators": ["\n\n", "\n", ". ", " ", ""]
            }
        }
    }
}
```

### ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²

```python
# ÐžÐ¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð´Ð»Ñ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… ÑÑ†ÐµÐ½Ð°Ñ€Ð¸ÐµÐ²
parameter_optimization = {
    "chunk_size": {
        "small_chunks": {
            "size": 200-500,
            "use_case": "Ð¢Ð¾Ñ‡Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº, ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹",
            "pros": ["Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ", "Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº"],
            "cons": ["ÐŸÐ¾Ñ‚ÐµÑ€Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°", "Ð‘Ð¾Ð»ÑŒÑˆÐµ Ñ‡Ð°Ð½ÐºÐ¾Ð²"]
        },
        
        "medium_chunks": {
            "size": 500-1500,
            "use_case": "ÐžÐ±Ñ‰ÐµÐµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ, RAG ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹",
            "pros": ["Ð‘Ð°Ð»Ð°Ð½Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚Ð¸ Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°"],
            "cons": ["ÐšÐ¾Ð¼Ð¿Ñ€Ð¾Ð¼Ð¸ÑÑÐ½Ð¾Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ"]
        },
        
        "large_chunks": {
            "size": 1500-3000,
            "use_case": "Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°, ÑÑƒÐ¼Ð¼Ð°Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ñ",
            "pros": ["ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚"],
            "cons": ["ÐœÐµÐ´Ð»ÐµÐ½Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº", "ÐœÐµÐ½ÑŒÑˆÐ°Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ"]
        }
    },
    
    "chunk_overlap": {
        "no_overlap": {
            "overlap": 0,
            "use_case": "Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð² ÐºÐ°Ð¶Ð´Ð¾Ð¼ Ñ‡Ð°Ð½ÐºÐµ",
            "pros": ["ÐÐµÑ‚ Ð´ÑƒÐ±Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ"],
            "cons": ["ÐŸÐ¾Ñ‚ÐµÑ€Ñ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð° Ð½Ð° Ð³Ñ€Ð°Ð½Ð¸Ñ†Ð°Ñ…"]
        },
        
        "small_overlap": {
            "overlap": "10-15% Ð¾Ñ‚ chunk_size",
            "use_case": "ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð´ÑƒÐ±Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ",
            "pros": ["Ð­ÐºÐ¾Ð½Ð¾Ð¼Ð¸Ñ Ð¼ÐµÑÑ‚Ð°", "ÐÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚"],
            "cons": ["ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð½Ð°Ñ ÑÐ²ÑÐ·Ð½Ð¾ÑÑ‚ÑŒ"]
        },
        
        "medium_overlap": {
            "overlap": "15-25% Ð¾Ñ‚ chunk_size",
            "use_case": "Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð¾Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ",
            "pros": ["Ð¥Ð¾Ñ€Ð¾ÑˆÐ¸Ð¹ Ð±Ð°Ð»Ð°Ð½Ñ"],
            "cons": ["Ð£Ð¼ÐµÑ€ÐµÐ½Ð½Ð¾Ðµ Ð´ÑƒÐ±Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ"]
        },
        
        "large_overlap": {
            "overlap": "25-40% Ð¾Ñ‚ chunk_size",
            "use_case": "ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ ÑÐ²ÑÐ·Ð½Ð¾ÑÑ‚ÑŒ",
            "pros": ["ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð°Ñ ÑÐ²ÑÐ·Ð½Ð¾ÑÑ‚ÑŒ"],
            "cons": ["Ð—Ð½Ð°Ñ‡Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð´ÑƒÐ±Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ"]
        }
    }
}
```

## ÐŸÑ€Ð¾Ð´Ð²Ð¸Ð½ÑƒÑ‚Ñ‹Ðµ Ñ‚ÐµÑ…Ð½Ð¸ÐºÐ¸ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ñ

### ÐÐ´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð¾Ðµ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ

```python
class AdaptiveTextSplitter:
    def __init__(self, base_chunk_size=1000, min_chunk_size=200, max_chunk_size=2000):
        self.base_chunk_size = base_chunk_size
        self.min_chunk_size = min_chunk_size
        self.max_chunk_size = max_chunk_size
    
    def split_text(self, text, document_type="general"):
        # ÐÐ½Ð°Ð»Ð¸Ð· Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸Ðº Ñ‚ÐµÐºÑÑ‚Ð°
        text_stats = self.analyze_text(text)
        
        # ÐÐ´Ð°Ð¿Ñ‚Ð°Ñ†Ð¸Ñ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
        adapted_params = self.adapt_parameters(text_stats, document_type)
        
        # Ð’Ñ‹Ð±Ð¾Ñ€ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»Ñ
        splitter = self.select_splitter(adapted_params)
        
        return splitter.split_text(text)
    
    def analyze_text(self, text):
        return {
            "length": len(text),
            "avg_sentence_length": self.calculate_avg_sentence_length(text),
            "paragraph_count": text.count('\n\n'),
            "has_code": self.detect_code_blocks(text),
            "has_tables": self.detect_tables(text),
            "language": self.detect_language(text)
        }
    
    def adapt_parameters(self, stats, document_type):
        # Ð›Ð¾Ð³Ð¸ÐºÐ° Ð°Ð´Ð°Ð¿Ñ‚Ð°Ñ†Ð¸Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð²
        if stats["has_code"]:
            return {"chunk_size": 1500, "overlap": 300}
        elif stats["avg_sentence_length"] > 100:
            return {"chunk_size": 1200, "overlap": 250}
        else:
            return {"chunk_size": 1000, "overlap": 200}
```

### Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ

```python
class SemanticTextSplitter:
    def __init__(self, embedding_model, similarity_threshold=0.8):
        self.embedding_model = embedding_model
        self.similarity_threshold = similarity_threshold
    
    def split_text(self, text):
        # Ð Ð°Ð·Ð±Ð¸ÐµÐ½Ð¸Ðµ Ð½Ð° Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
        sentences = self.split_into_sentences(text)
        
        # ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð¾Ð² Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ
        embeddings = [self.embedding_model.embed(sent) for sent in sentences]
        
        # Ð“Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ° ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ñ… Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹
        chunks = self.group_by_similarity(sentences, embeddings)
        
        return chunks
    
    def group_by_similarity(self, sentences, embeddings):
        chunks = []
        current_chunk = [sentences[0]]
        current_embedding = embeddings[0]
        
        for i in range(1, len(sentences)):
            similarity = self.cosine_similarity(current_embedding, embeddings[i])
            
            if similarity >= self.similarity_threshold:
                current_chunk.append(sentences[i])
                # ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÐ¼Ð±ÐµÐ´Ð´Ð¸Ð½Ð³Ð° Ñ‡Ð°Ð½ÐºÐ°
                current_embedding = self.update_chunk_embedding(
                    current_embedding, embeddings[i]
                )
            else:
                chunks.append(' '.join(current_chunk))
                current_chunk = [sentences[i]]
                current_embedding = embeddings[i]
        
        if current_chunk:
            chunks.append(' '.join(current_chunk))
        
        return chunks
```

### ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð½Ð¾-Ð¾ÑÐ²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð½Ð¾Ðµ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ

```python
class ContextAwareTextSplitter:
    def __init__(self, chunk_size=1000, overlap=200):
        self.chunk_size = chunk_size
        self.overlap = overlap
    
    def split_text(self, text, metadata=None):
        # Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸
        structure = self.extract_structure(text)
        
        # Ð Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹
        chunks = self.structure_aware_split(text, structure)
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð½Ñ‹Ñ… Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ñ…
        enriched_chunks = self.add_context_metadata(chunks, structure, metadata)
        
        return enriched_chunks
    
    def extract_structure(self, text):
        return {
            "headers": self.find_headers(text),
            "lists": self.find_lists(text),
            "tables": self.find_tables(text),
            "code_blocks": self.find_code_blocks(text),
            "quotes": self.find_quotes(text)
        }
    
    def add_context_metadata(self, chunks, structure, metadata):
        enriched = []
        
        for i, chunk in enumerate(chunks):
            chunk_metadata = {
                "chunk_index": i,
                "total_chunks": len(chunks),
                "structure_elements": self.identify_elements_in_chunk(chunk, structure),
                "previous_context": chunks[i-1][-100:] if i > 0 else None,
                "next_context": chunks[i+1][:100] if i < len(chunks)-1 else None
            }
            
            if metadata:
                chunk_metadata.update(metadata)
            
            enriched.append({
                "content": chunk,
                "metadata": chunk_metadata
            })
        
        return enriched
```

## Ð£Ð·Ð»Ñ‹ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÐµÐ¹ Ñ‚ÐµÐºÑÑ‚Ð°:

* [Ð¡Ð¸Ð¼Ð²Ð¾Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÑŒ Ñ‚ÐµÐºÑÑ‚Ð°](character-text-splitter.md)
* [Ð Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÑŒ ÐºÐ¾Ð´Ð°](code-text-splitter.md)
* [HTML-to-Markdown Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÑŒ Ñ‚ÐµÐºÑÑ‚Ð°](html-to-markdown-text-splitter.md)
* [Markdown Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÑŒ Ñ‚ÐµÐºÑÑ‚Ð°](markdown-text-splitter.md)
* [Ð ÐµÐºÑƒÑ€ÑÐ¸Ð²Ð½Ñ‹Ð¹ ÑÐ¸Ð¼Ð²Ð¾Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÑŒ Ñ‚ÐµÐºÑÑ‚Ð°](recursive-character-text-splitter.md)
* [Ð¢Ð¾ÐºÐµÐ½Ð½Ñ‹Ð¹ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÑŒ Ñ‚ÐµÐºÑÑ‚Ð°](token-text-splitter.md)

## Ð›ÑƒÑ‡ÑˆÐ¸Ðµ Ð¿Ñ€Ð°ÐºÑ‚Ð¸ÐºÐ¸

### Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ

```python
# Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÐµÐ¹
class TextSplitterTester:
    def __init__(self):
        self.metrics = {}
    
    def test_splitter(self, splitter, test_documents):
        results = {
            "chunk_size_distribution": [],
            "overlap_effectiveness": [],
            "semantic_coherence": [],
            "processing_time": []
        }
        
        for doc in test_documents:
            start_time = time.time()
            chunks = splitter.split_text(doc["content"])
            processing_time = time.time() - start_time
            
            # ÐÐ½Ð°Ð»Ð¸Ð· Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
            results["chunk_size_distribution"].extend([len(chunk) for chunk in chunks])
            results["overlap_effectiveness"].append(self.measure_overlap_quality(chunks))
            results["semantic_coherence"].append(self.measure_coherence(chunks))
            results["processing_time"].append(processing_time)
        
        return self.calculate_metrics(results)
    
    def measure_overlap_quality(self, chunks):
        # Ð˜Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð° Ð¿ÐµÑ€ÐµÐºÑ€Ñ‹Ñ‚Ð¸Ð¹
        overlap_scores = []
        for i in range(len(chunks) - 1):
            overlap = self.find_overlap(chunks[i], chunks[i+1])
            score = self.evaluate_overlap_quality(overlap)
            overlap_scores.append(score)
        return sum(overlap_scores) / len(overlap_scores) if overlap_scores else 0
    
    def measure_coherence(self, chunks):
        # Ð˜Ð·Ð¼ÐµÑ€ÐµÐ½Ð¸Ðµ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ ÑÐ²ÑÐ·Ð½Ð¾ÑÑ‚Ð¸
        coherence_scores = []
        for chunk in chunks:
            score = self.calculate_coherence_score(chunk)
            coherence_scores.append(score)
        return sum(coherence_scores) / len(coherence_scores)
```

### ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸

```python
# ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÐµÐ¹
class SplitterPerformanceMonitor:
    def __init__(self):
        self.metrics = {
            "processing_times": [],
            "chunk_counts": [],
            "memory_usage": [],
            "error_rates": []
        }
    
    def monitor_splitting(self, splitter_func, text):
        start_time = time.time()
        start_memory = self.get_memory_usage()
        
        try:
            chunks = splitter_func(text)
            success = True
            error = None
        except Exception as e:
            chunks = []
            success = False
            error = str(e)
        
        end_time = time.time()
        end_memory = self.get_memory_usage()
        
        # Ð—Ð°Ð¿Ð¸ÑÑŒ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
        self.metrics["processing_times"].append(end_time - start_time)
        self.metrics["chunk_counts"].append(len(chunks))
        self.metrics["memory_usage"].append(end_memory - start_memory)
        self.metrics["error_rates"].append(0 if success else 1)
        
        return {
            "chunks": chunks,
            "success": success,
            "error": error,
            "processing_time": end_time - start_time,
            "memory_delta": end_memory - start_memory
        }
```

## Ð—Ð°ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ

Ð Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»Ð¸ Ñ‚ÐµÐºÑÑ‚Ð° ÑÐ²Ð»ÑÑŽÑ‚ÑÑ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð²Ð°Ð¶Ð½Ñ‹Ð¼ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¾Ð¼ Ð² ÑÐ¸ÑÑ‚ÐµÐ¼Ð°Ñ… Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð³Ð¾ ÑÐ·Ñ‹ÐºÐ° Ð¸ RAG Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð°Ñ…. ÐŸÑ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»Ñ Ð¼Ð¾Ð¶ÐµÑ‚ Ð·Ð½Ð°Ñ‡Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð¿Ð¾Ð²Ð»Ð¸ÑÑ‚ÑŒ Ð½Ð° ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°, Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð¸ Ð¾Ð±Ñ‰ÑƒÑŽ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹.

ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿Ñ‹ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾Ð³Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÐµÐ¹ Ñ‚ÐµÐºÑÑ‚Ð°:
- **Ð’Ñ‹Ð±Ð¸Ñ€Ð°Ð¹Ñ‚Ðµ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»ÑŒ** Ð² ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ð¸ Ñ Ñ‚Ð¸Ð¿Ð¾Ð¼ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°
- **ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°Ð¹Ñ‚Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹** Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð²Ð°ÑˆÐ¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ð¹
- **Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸** Ð´Ð»Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
- **ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€ÑŒÑ‚Ðµ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ** Ð¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ñ
- **Ð£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ð¹Ñ‚Ðµ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸** Ð¿Ñ€Ð¸ Ð²Ñ‹Ð±Ð¾Ñ€Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð° Ñ‡Ð°Ð½ÐºÐ¾Ð²
- **Ð‘Ð°Ð»Ð°Ð½ÑÐ¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼** Ð¿Ñ€Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐµ Ð¿ÐµÑ€ÐµÐºÑ€Ñ‹Ñ‚Ð¸Ð¹
